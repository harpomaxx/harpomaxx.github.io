<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>supervised learning on Computer Science Notes</title>
		<link>https://harpomaxx.github.io/tags/supervised-learning/</link>
		<description>Recent content in supervised learning on harpomaxx.github.io</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>Â© Copyright [Harpo MAxx] MIT LICENSE</copyright>
		<lastBuildDate>Sun, 12 Sep 2021 00:00:00 +0000</lastBuildDate>
		
		<atom:link href="https://harpomaxx.github.io/tags/supervised-learning/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>SHAP values with examples applied to a multi-classification problem.</title>
			<link>https://harpomaxx.github.io/post/shap-values/</link>
			<pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
			
			<guid>https://harpomaxx.github.io/post/shap-values/</guid>
			<description>
				
				We can not continue treating our models as black boxes anymore. Remember, nobody trusts computers for making a very important decision (yet!). That&#39;s by the prediction of a Machine Learning model has become a major research topic. SHAP is a very nice approach for providing interpretability to any machine learning model.  For multi-classification problems, however, documentation and examples are not very clear. [8min read]
				
			</description>
		</item>
		<item>
			<title>Are Boosting Algorithms the new baseline model for your Tabular data? Part 1</title>
			<link>https://harpomaxx.github.io/post/are-boosting-algorithms-the-new-baseline-models/</link>
			<pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
			
			<guid>https://harpomaxx.github.io/post/are-boosting-algorithms-the-new-baseline-models/</guid>
			<description>
				
				Neural networks rule the world of machine learning IFF, you have a lot of data, and just for a reduced set of problems. The fact is that for heterogeneous (numerical and categorical) tabular data, decision trees are still one of the best options. Also, they have the benefit of being (more) explainable to the customer. Boosting decision trees are among the most successful algorithms in data science competitions, but could they replace Random Forest? The absolute leader, when you try a first model in your data.[updated]
				
			</description>
		</item>
		
	</channel>
</rss>
